A good overview of various Markov-chain Monte Carlo methods is available [here](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.7133&rep=rep1&type=pdf).

### Metropolis-Hastings sampling

_Metropolis-Hastings_ sampling (M-H) aims to draw samples from a posterior using only a _posterior-ish function_ (e.g. the unnormalized posterior given some measured data) and a _proposal function_. M-H is provided with an initial draw from the posterior and aims to generate a series of samples by moving from that initial draw to the next, following a certain rule. (More details can be found [here](http://www.journalofvision.org/content/5/5/8.short).)

The posterior-ish function is used to determine whether or not the next potential sample is in a region of higher posterior probability compared with the previous sample.

The proposal function describes how to generate the next potential sample. (If the proposal function is symmetric this sampling procedure is sometimes called _Metropolis samping_. If it is independent of the location of the most recent sample it is called an _independent sampler_.)

![Example of proposal function of M-H](/img/proposal-fcn.png?raw=true "Example of proposal function of M-H")

#### Example 1: Generating samples from weibull pdf

The function `example_1()` function in `examples.py` currently uses a gaussian proposal function to draw samples from a weibull pdf with given shape and scale parameters. As you can see, the samples generated by `metropolis_hastings()` (after pruning) are a close match to the actual weibull pdf:

![Example of posterior samples from M-H](/img/example-1.png?raw=true "Example of posterior samples from M-H")

#### Example 2: Fitting weibull scale parameter of data generated by a weibull pdf

But `example_1()` is more like a sanity-check, isn't it? If we hand M-H the pdf, it can generate samples from that pdf--not that impressive.

On the other hand, `example_2()` is a little closer to what we'd want M-H to do. It simulates data from a weibull pdf given shape and scale parameters, and M-H tries to generate samples of (i.e. fit) the shape parameter, by calculating the log-likelihood of the simulated data.

So now, the generated samples are all estimates of the shape parameter. The shape parameter used to simulate the data was 3. The estimates cluster around 3, which is good, though this is not always the case given multiple simulations.

![Example of posterior samples from M-H](/img/example-2.png?raw=true "Example of posterior samples from M-H")

### Simulated annealing

Metropolis-Hastings aims to approximate the entire posterior distribution. However, in the case of fitting, often all you want is the maximum a posteriori (MAP) estimate of the posterior: in other words, you don't need to approximate the entire posterior--you just want to know the mode!

Simulated annealing (good overview [here](http://stuff.mit.edu/~dbertsim/papers/Optimization/Simulated%20annealing.pdf)) is a generalization of Metropolis-Hastings, with an added parameter function called the "cooling schedule" that is non-increasing with each iteration of your sampler. 

Using M-H to approximate the mode of the posterior is inefficient since it tries to spread itself along the entire posterior. Simulated annealing, however, uses its cooling schedule function to slowly hone in on the mode of the posterior.

One common choice of a cooling schedule `T` is as follows:

    T = lambda i: (C*log(i + T_0)) − 1 # for some C and T_0

(The only rules for `T` is that it must be non-increasing, and as i -> ∞, T(i) -> 0.)

Now, at each iteration, the `p_pdf_fcn` of `metropolis_hastings()` is instead calculated as `p_pdf_fcn(x)^(1/T_i)`, where i is the current iteration of the sampler.

The very last sample generated is your MAP estimate of the posterior.


### Future examples

* Example 3: Fitting scale _and_ shape parameters of data generated by a weibull pdf.

* Example 4: Fitting with a prior over parameters.

* Example 5: Comparing M-H to simply minimizing likelihood.

* Example 6: Simulated annealing MAP estimate.
